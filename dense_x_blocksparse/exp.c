

#include<stdio.h>
#include<time.h>
#include "../common/timing.h"
#include "../common/colmajor.h"
#include "../common/sparse.h"
 




void blocksparse_snb_nnz1 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_198:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_199:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_199\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_198\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};




void blocksparse_snb_nnz2 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_200:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_201:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_201\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_200\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};




void blocksparse_snb_nnz3 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_202:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_203:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_203\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_202\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};




void blocksparse_snb_nnz4 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_204:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_205:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_205\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_204\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};




void blocksparse_snb_nnz5 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_206:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_207:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_207\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_206\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};




void blocksparse_snb_nnz6 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_208:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_209:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_209\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_208\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};




void blocksparse_snb_nnz7 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_210:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_211:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_211\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_210\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};




void blocksparse_snb_nnz8 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_212:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_213:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_213\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_212\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};




void blocksparse_snb_nnz9 (const double* A, const double* B, double* C) {
  __asm__ __volatile__(
                       "mov $0, %%r13\n\t"
                       "loop_top_214:\n\t"
                       "mov $0, %%r12\n\t"
                       "loop_top_215:\n\t"
                       "vmovapd 0(%%rdx), %%ymm7\n\t"
                       "vmovapd 32(%%rdx), %%ymm8\n\t"
                       "vmovapd 64(%%rdx), %%ymm9\n\t"
                       "vmovapd 384(%%rdx), %%ymm10\n\t"
                       "vmovapd 416(%%rdx), %%ymm11\n\t"
                       "vmovapd 448(%%rdx), %%ymm12\n\t"
                       "vmovapd 768(%%rdx), %%ymm13\n\t"
                       "vmovapd 800(%%rdx), %%ymm14\n\t"
                       "vmovapd 832(%%rdx), %%ymm15\n\t"
                       "vbroadcastsd 0(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 72(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 144(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 8(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 80(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 152(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 16(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 88(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 160(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 24(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 96(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 168(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 32(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 104(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 176(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 40(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 112(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 184(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 48(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 120(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 192(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 56(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 128(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 200(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vbroadcastsd 64(%%rsi), %%ymm0\n\t"
                       "vbroadcastsd 136(%%rsi), %%ymm1\n\t"
                       "vbroadcastsd 208(%%rsi), %%ymm2\n\t"
                       "vmovapd 0(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm7, %%ymm7\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm10, %%ymm10\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm4\n\t"
                       "vaddpd %%ymm4, %%ymm13, %%ymm13\n\t"
                       "vmovapd 32(%%rdi), %%ymm3\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm8, %%ymm8\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm11, %%ymm11\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm5\n\t"
                       "vaddpd %%ymm5, %%ymm14, %%ymm14\n\t"
                       "vmovapd 64(%%rdi), %%ymm3\n\t"
                       "addq $384, %%rdi    ; Matrix A cursor moved down=0, right=1 cells\n\t"
                       "vmulpd %%ymm3, %%ymm0, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm9, %%ymm9\n\t"
                       "vmulpd %%ymm3, %%ymm1, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm12, %%ymm12\n\t"
                       "vmulpd %%ymm3, %%ymm2, %%ymm6\n\t"
                       "vaddpd %%ymm6, %%ymm15, %%ymm15\n\t"
                       "vmovapd %%ymm7, 0(%%rdx)\n\t"
                       "vmovapd %%ymm8, 32(%%rdx)\n\t"
                       "vmovapd %%ymm9, 64(%%rdx)\n\t"
                       "vmovapd %%ymm10, 384(%%rdx)\n\t"
                       "vmovapd %%ymm11, 416(%%rdx)\n\t"
                       "vmovapd %%ymm12, 448(%%rdx)\n\t"
                       "vmovapd %%ymm13, 768(%%rdx)\n\t"
                       "vmovapd %%ymm14, 800(%%rdx)\n\t"
                       "vmovapd %%ymm15, 832(%%rdx)\n\t"
                       "addq $96, %%rdx    ; Matrix C cursor moved down=1, right=0 blocks\n\t"
                       "addq $-3360, %%rdi    ; Matrix A cursor moved down=1, right=-1 blocks\n\t"
                       "addq $12, %%r12\n\t"
                       "cmpq $48, %%r12\n\t"
                       "jl loop_top_215\n\t"
                       "addq $768, %%rdx    ; Matrix C cursor moved down=-48, right=3 cells\n\t"
                       "addq $216, %%rsi    ; Matrix B cursor moved right 1 pattern-blocks\n\t"
                       "addq $-384, %%rdi    ; Matrix A cursor moved down=-48, right=0 cells\n\t"
                       "addq $3, %%r13\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl loop_top_214\n\t"
                       : : "m"(A), "m"(B), "m"(C) : "r12","r13","rdi","rdx","rsi","ymm0","ymm1","ymm10","ymm11","ymm12","ymm13","ymm14","ymm15","ymm2","ymm3","ymm4","ymm5","ymm6","ymm7","ymm8","ymm9");
};


 


int main(int argc, char ** argv) {

    clock_t ticks_before, ticks_after;
    uint64_t cycles_before, cycles_after;
    struct colmajor A = zeros(48, 9);
    struct colmajor C_expected = zeros(48, 9);
    struct colmajor C_actual = zeros(48, 9);
    struct sparse_csc B = create_sparse(9, 9);
    fill_dense(A, 1, 2);
     



    /***** Testing blocksparse_snb_nnz1 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 0, 0, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz1(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz1, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    


    /***** Testing blocksparse_snb_nnz2 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 1, 1, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz2(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz2, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    


    /***** Testing blocksparse_snb_nnz3 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 2, 2, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz3(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz3, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    


    /***** Testing blocksparse_snb_nnz4 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 0, 1, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz4(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz4, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    


    /***** Testing blocksparse_snb_nnz5 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 1, 2, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz5(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz5, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    


    /***** Testing blocksparse_snb_nnz6 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 0, 2, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz6(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz6, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    


    /***** Testing blocksparse_snb_nnz7 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 1, 0, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz7(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz7, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    


    /***** Testing blocksparse_snb_nnz8 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 2, 1, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz8(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz8, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    


    /***** Testing blocksparse_snb_nnz9 *****/

    reset(&C_expected);
    reset(&C_actual);
    update_pattern(&B, 2, 0, 1);
    fill(&B, 1, 2);
    sparse2dense(&B, &B_dense);

    gemm(A.values, B_dense.values, C_expected.values);
    assert_equals(&C_expected, &C_actual);

    ticks_before = clock();
    cycles_before = tsc();
    for (int t=0; t<2000; t++)
        blocksparse_snb_nnz9(A.values, B.values, C_actual.values);
    ticks_after = clock();
    cycles_after = tsc();

    printf("blocksparse_snb_nnz9, %lld, %ld\n",
        cycles_after - cycles_before,
        ticks_after - ticks_before );
    

 



}
