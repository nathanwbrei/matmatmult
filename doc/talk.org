
* What is the problem I am trying to solve?
** Earthquakes. What does SeisSol let you predict about earthquakes?
** ADER-DG. How is this different from finite elements?
** Small local matrix multiplications with low communication overhead. How is this possible?
** Innermost compute kernel: star matrix. Goal: Make this slightly faster?
** sparse*dense != dense*sparse

* Why is this difficult?
** What is KNL?
    - Multi/manycore (~64) coprocessor/processor
    - AVX512 instruction set with 32x 64-byte vector registers
    - Taking over top500 list
 
** Why is KNL bad for sparse matrix operations?
    - Lower clock frequency
    - Narrow oooE issue width
    - Large instruction size (Cannot stream FMA instructions)  // HOW TRUE IS THIS?
    - Scalar instructions run slower
    - Fewer execution units? 

    - Wide vector registers
    - 32(!) named vector registers, 16 scalar registers
    - FMA instructions include broadcast and masking => fewer instructions, registers needed total
    - Gather/scatter, blending operations
    - Large reorder buffer
    - TODO: Why do we use a 1d register blocking?

** Consequence: 
    - Code optimal for SNB/HSW is probably unoptimal for KNL
    - Not obvious whether _sth_ holds

* What solutions exist?
** Naive solution: CSC
   + Low memory use
   - Sparsity patterns not known at compile time -> Index lookups -> Control dependencies

** Unrolled solution: Breuer
   + Fine-grained control of vectorization
   + No index lookups, few or no loops

   + Throttles instruction cache
   + Generated C++ code which compiler is not able to optimize for avx512 

** Dense solution: Libxsmm
   + Efficient use of KNL hardware
   + High total GFlops
   + Low nonzero GFlops
   + Low time-to-solution
   + More memory movement -> Roofline model
 
* My work: Finding a compromise between full unrolling and 


** Goals
   - Explore the parameter space of different families of algorithms:
     + dense-sparse csc, tiledcsc, blockcsc
     + sparse-dense breuer, blended, shifted-load, scalar, gather-scatter

   - Independent variables include matrix size, overall sparsity, sparsity patterns, 
         block size, register usage, loop unroll depth, instruction reordering

   - Identify bottlenecks and understand how they constrain the regions of 
         parameter space in which they are useful

   
** Code generation

*** Approach

     - Choice of generated language:

       + C++ 
         - Optimizer has inside knowledge
         - Compile-time specialization only via macros, templates, constexprs
         - Syntax is too complex to capture in generator. Nested strings are error-prone. 
         - Alg designer must infer what assembly the compiler will omit

       + ASM
         - Designer needs to be thinking in terms of assembly anyway
         - Syntax is simple enough to capture an exact AST
         - Full AST allows dependency analysis, optimizations such as instruction reordering, 
           simulation of caches, visualization

       + Compromise: Algorithms expressed in assembly AST, harness expressed in C++

        
     - Choice of generation language:
       + C++
         - Strong static typing and manual memory management 
           hinder interactivity, increase feedback time

       + Python
         + Existing code generation for SeisSol, e.g. sparse matrix encodings which could possibly be reused
         + Able to leverage SciPy, Matplotlib
         + Lack of type safety somewhat ameliorated in Python 3.6
         
       + Julia
         + Expressive macros, algebraic datatypes, multiple dispatch
         + Significant support for code generation
         + Ability to introspect both LLVM IR and x86 assembly from the Julia interpreter
         + Significant churn and breaking changes.
         + Difficult to build a standalone executable which can even run on the cluster, 
           particularly while using the codegen features
         + Doesn't allow interacting with assembly directly

       + Racket
         + Modern lisp with large user base, well-suited to language design
         + Optional typing, algebraic datatypes, pattern matching
         + Possibility to write an entirely new syntax DSL
         + Unlikely anyone would be able to understand the code I wrote

         
       + Blocks, Loops, and unrolling
         - Comments, indentation, GAS vs intel vs inline GAS syntax
         - 

       + Matrix cursor

       + Simulation
         - 


** Experiment framework
   - 

   - 



** My results: 
