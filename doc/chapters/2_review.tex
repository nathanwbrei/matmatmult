\chapter{Background}
\label{chapter:review}

\section{The BLAS abstraction}

Dense and sparse matrix multiplication account for a surprising fraction of all computation, particularly in scientific and engineering fields. Since any optimization or algorithmic improvement has the potential to improve the performance of programs across the board, these algorithms have been organized under a series of common interfaces. Not only does this make it easy to reuse the best known implementation of many fundamental linear algebra operations, but it also confers other advantages: robustness is increased by the careful handling of edge cases, portability is increased because a programmer can link to the best implementation for their target architecture, and readability is increased because numerical algorithms can all work at the same abstraction level. The first such interface, \gls{BLAS}, was introduced in 1979 by Lawson~\cite{Lawson:1979:BLA:355841.355847} and only supported dense vector and matrix operations. Later interfaces, such as LAPACK, build upon and extend \gls{BLAS} to support increasingly complex operations; the history and design of such interfaces is covered by Dongarra in~\cite{Dongarra:1998:NLA:552704}. 

Most of the naming conventions used in this work follow those of BLAS and its successors. The arguments for each operation get quite complicated (see~\cite{IntelCSCMM}), but for our purposes they can be simplified as shown in Figure~\ref{fig:blas}. These conventions have propagated to libraries including MKL and libxsmm.

\begin{figure}
\begin{verbatim}
// C = alpha*A*B + beta*C
dgemm(m, n, k, alpha, A, lda, B, ldb, beta, C, ldc)
\end{verbatim}

\begin{tabular}{ll}
	\toprule
	Variable    &  Meaning \\
	\midrule
	dgemm & Double General Matrix Multiplication \\
	alpha & A scalar constant \\
	beta  & A scalar constant \\
	A     & A matrix of doubles, in dense column-major format unless sparse \\
	B     & A matrix of doubles, in dense column-major format unless sparse \\
	C     & A matrix of doubles, in dense column-major format \\
	m     & The number of rows of C and A \\
	n     & The number of columns of C and B \\
	k     & The number of columns in A and rows in B \\
	lda   & The leading dimension (offset between columns) of A; zero indicates sparse \\
	ldb   & The leading dimension (offset between columns) of B; zero indicates sparse \\
	ldc   & The leading dimension (offset between columns) of C \\


	\bottomrule
\end{tabular}
\caption{Simplified BLAS naming conventions for general matrix multiplication}
\label{fig:blas}
\end{figure}


A sparse BLAS interface was not standardized until 2002, as described by Duff in~\cite{Duff:2002:OSB:567806.567810}. Compared with the dense case, sparse matrix operations are considerably more difficult to pin down because the performance of each operation depends heavily -- often asymptotically -- on the memory layout, which in turn depends on both the chosen storage format and the sparsity pattern, which is often known only at runtime. The choice of storage format is tightly coupled with the implementation of the operations, making abstraction difficult. Thus there are a multitude of different storage formats, with not entirely consistent naming conventions. The formats used in this work are described in Figure~\ref{fig:formats} and introduced as they are needed in Chapter~\ref{chapter:algs}. Ultimately, a sparse BLAS works well when the matrices are large, are constrained to a common format such as CSC, and have unpredictable or nonconstant sparsity patterns; otherwise a custom implementation might be able to do much better.


\begin{figure}

\begin{description}
	\item[Dense (DNS)] Column-major dense format, possibly padded

	\item[Coordinate format (COO)] Entries are stored in an array alongside their row and column indices.

	\item[Compressed sparse column (CSC)] Nonzero entries are stored top to bottom, then left to right. Row indices are used but column indices are not; pointers to the start of each column are used instead. 

	\item[Compressed sparse row (CSR)] The row-major equivalent of CSC

	\item[Block sparse column (BSC)] The matrix is subdivided into blocks, each of which is either empty or dense. The blocks are ordered and indexed in CSC format. 

	\item[Block sparse row (BSR)] The row-major equivalent of BSC

	\item[Block compressed sparse column (BCSC)] The matrix is subdivided into blocks, each of which might be zero, or might have its own sparsity pattern. There are effectively two levels of CSC. 

	This format is particularly important for us for two reasons: Firstly, all of the entries in one block are located together. Secondly, the memory offset from the first entry in the block to any other entry in the block is not influenced by neighboring blocks. 

	\item[Block compressed sparse row (BCSR)] The row-major equivalent of BCSC

	\item[Virtual... (V...)] A sparse format where all of the index information has been omitted; all that is left is an array containing the nonzero values.

\end{description}
\caption{Descriptions of different sparse matrix formats \emph{as used in this work}. Naming conventions vary between literature; pay attention to the distinction between BSC and BCSC. }
\label{fig:formats}
\end{figure}


In 2008, Goto and Geijn~\cite{Goto:2008:AHM:1356052.1356053} devised a general framework for designing optimized kernels for large dense matrix multiplication. They start by exploring the space of recursive block decompositions, and then they build up a model of the memory hierarchy which allows them to prune their design space, decide what data needs to be packed, and decide what block sizes are best. Thus they arrive at an algorithm for designing a performant matrix kernel. However, their reasoning only applies to matrices which are large enough to involve all the levels of the memory hierarchy. They only briefly discuss the design of the innermost kernel, which is small enough to fit in registers. 


\section{Outer-product formulation}

Luckily, the state of the art innermost kernel is discussed in depth by Heinecke~\cite{Heinecke:2016:LAS:3014904.3015017} with regards to libxsmm. It is known as the outer-product formulation. An excerpt from a kernel optimized for KNL is provided in Figure~\ref{fig:outerproduct}. The basic idea is to load a block of C, column by column, into the vector registers. We then stream loads of columns of A. We wish to perform the vector outer-product of each column of A with the corresponding row of B, and accumulate these in the C block. This is accomplished by repeatedly loading a \emph{scalar} value of B, broadcasting it into a vector register, multiplying the broadcasted value of B with the current column of A, and adding it to the correct column of the C block. Once all of the columns of A have been processed, the C block is stored back down to memory and the algorithm moves on to the next block.

Libxsmm performs a number of optimizations specifically for KNL. The most noticeable is that a 1D blocking of A and C is chosen, partly because of the convenience of that tile size, and partly because additional loads of A columns interfere with vector arithmetic due to the KNL's narrow issue width. A second problem is that B is stored by columns but accessed by rows, so the memory addresses will likely contain offsets greater than $128\times 8$, causing the size of the FMA instructions to increase to 10 bytes, and hitting the instruction cache bandwidth bottleneck as discussed in Section~\ref{section:knl}. The solution is to switch from pointer-offset addressing, e.g. \verb|rsi + 198|, to scale-index-base addressing, e.g. \verb|rsi + 8 * r13 + 22|, which uses two registers and two hardcoded values to express the same address. This makes the assembly code much harder to read. 


\begin{figure}[ht]
\begin{minted}[fontsize=\footnotesize]{gas}
# Load C register block
vmovapd 0(%rdx),  %zmm16                                 # load C[:,0]
vmovapd 64(%rdx), %zmm17                                 # load C[:,1]
vmovapd 128(%rdx), %zmm18                                # load C[:,2]
# ...

# Load A register block
vmovapd 0(%rdi), %zmm0                                   # load A[:,0]
vmovapd 64(%rdi), %zmm1                                  # load A[:,1]
# ...

# Outer product of A[:,0] * B[0,:]
vfmadd231pd 0(%rsi) {1to8}, %zmm0, %zmm16                # C[:,0] += A[:,0] .* B[0,0]
vfmadd231pd 0(%rsi,%r15,1) {1to8}, %zmm0, %zmm17         # C[:,1] += A[:,0] .* B[0,1]
vfmadd231pd 0(%rsi,%r15,2) {1to8}, %zmm0, %zmm18         # C[:,2] += A[:,0] .* B[0,2]
# ...

# Outer product of A[:,1] * B[1,:]
vfmadd231pd 8(%rsi) {1to8}, %zmm1, %zmm16                # C[:,0] += A[:,1] .* B[1,0]
vfmadd231pd 8(%rsi,%r15,1) {1to8}, %zmm1, %zmm17         # C[:,0] += A[:,1] .* B[1,1]
vfmadd231pd 8(%rsi,%r15,2) {1to8}, %zmm1, %zmm18         # C[:,0] += A[:,1] .* B[1,2]
# ...
# More outer products ...

# Store C register block
vmovapd %zmm16, 0(%rdx)                                  # store C[:,0]
vmovapd %zmm17, 64(%rdx)                                 # store C[:,1]
vmovapd %zmm18, 128(%rdx)                                # store C[:,2]
# ...
\end{minted}
\caption{Example outer-product formulation generated by libxsmm specifically for KNL}
\label{fig:outerproduct}
\end{figure}



\section{The dense-by-sparse vs sparse-by-dense asymmetry}
\label{section:asymmetry}

This work 

(Dense $\times$ Sparse) $\neq$ (Sparse $\times$ Dense) due to vectorization

Choice of row-major vs column-major format determines which of the two vectorizes nicely: $(AB)^T = B^T A^T$

- Outer-product formulation
- Breuer
- MKL
- Row-major vs Column-major



\section{Naming conventions}

This work uses the BLAS naming conventions wherever possible. These conventions must be extended to handle 
Firstly, iteration variable names are derived from the size variable names by adding the suffix \py{-i}. Secondly, we wish to iterate not only over cells, but also blocks and vectors. The naming convention handles this via a prefix. In effect, \py{m,n,k} determine the iteration \emph{direction}, and the prefix determines the units. Finally, we introduce the direction \py{l} to handle the third dimension, when working with tensors. The complete grammar is provided in Figure~\ref{fig:grammar}. This convention adds much-needed predictability and ease of comprehension inside deeply nested loops. It also helps ensure that iteration variables stay within the correct range. The most common pattern is to iterate over matrix blocks, and then inside each block iterate over cells (for sparse matrices) and vectors (for dense matrices). An example of this is given below:

\begin{minted}{python}
for ki in range(k):
	print(B[ki,ni])
\end{minted}

\begin{figure}[tbh]
  \centering
  \begin{subfigure}[l]{0.48\textwidth}
      \begin{minted}[linenos=false,fontsize=\small]{text}
    <var>       ::= [<units>]<direction>[i]
    <units>     ::= b | B | v | V
    <direction> ::= m | n | k | l
  \end{minted}
  \end{subfigure}
  ~~~~
  \begin{subfigure}[r]{0.45\textwidth}
    \centering
    \begin{tabular}{cll}
		\toprule
		Units    & Mnemonic & Meaning \\
		\midrule

		none  & Cell          & Cells in the matrix      \\
		b     & Intra-block   & Cells in a block         \\
		B     & Inter-block   & Blocks in the matrix     \\
		v     & Intra-vector  & Cells in a block         \\
		V     & Inter-vector  & Vectors in a block       \\
		\bottomrule
	\end{tabular}
  \end{subfigure}
  \caption{Grammar for variable names.}
  \label{fig:grammar}
\end{figure}
